{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m venv env\n",
    "# !pip install -r \"C:/Users/msi/DS/Eye Disease Classification/requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6212bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create conda environment\n",
    "# !conda create --name cuda_venv\n",
    "# !conda activate cuda_venv\n",
    "\n",
    "# # Install pytorch following commands from https://pytorch.org/get-started/locally/\n",
    "# !conda install pytorch torchvision torchaudio pytorch-cuda=11.6 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b73c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "C:\\Users\\msi\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\msi\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adebd6af",
   "metadata": {},
   "source": [
    "Загружаем датасет (локально)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd576be",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"C:/Users/msi/DS/Eye Disease Classification/dataset/Augmented Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfcf134",
   "metadata": {},
   "source": [
    "Формируем датасет как словарь структуры:\n",
    "\n",
    "{\n",
    "    \"path\": <путь к фото>,\n",
    "    \"class\": <название класса>,\n",
    "    \"width\": <ширина>,\n",
    "    \"height\": <высота>\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be5b454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_eye_disease_dataset(\n",
    "    DATA_DIR: str, force_download: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Загружает и структурирует датасет\n",
    "    Возвращает DataFrame с путями к изображениям и метками классов\n",
    "    \"\"\"\n",
    "\n",
    "    # Выгружаем данные\n",
    "    if force_download or not DATA_DIR.exists():\n",
    "        print(\"Загружаю датасет...\")\n",
    "        DATA_DIR = kagglehub.dataset_download(\n",
    "            \"ruhulaminsharif/eye-disease-image-dataset\"\n",
    "        )\n",
    "        print(f\"Датасет загружен в директорию: {DATA_DIR}\")\n",
    "    else:\n",
    "        print(f\"Использую уже имеющийся датасет из директории: {DATA_DIR}\")\n",
    "\n",
    "    folders = os.listdir(DATA_DIR)\n",
    "    # Собираем метаданные\n",
    "    data = []\n",
    "    for class_name in folders:\n",
    "        class_dir = DATA_DIR / class_name\n",
    "        if not class_dir.exists():\n",
    "            continue\n",
    "\n",
    "        for img_path in class_dir.glob(\"*.jpg\"):\n",
    "            try:\n",
    "                # Проверка целостности изображений\n",
    "                with Image.open(img_path) as img:\n",
    "                    img.verify()\n",
    "\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"path\": str(img_path),\n",
    "                        \"class\": class_name,\n",
    "                        \"width\": img.width,\n",
    "                        \"height\": img.height,\n",
    "                    }\n",
    "                )\n",
    "            except (IOError, OSError) as e:\n",
    "                print(f\"Ошибка с изображением {img_path} - {str(e)}\")\n",
    "\n",
    "    # Формируем датафрейм\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Проверим распределение классов\n",
    "    class_dist = df[\"class\"].value_counts()\n",
    "    print(f\"Распределение классов: {class_dist}\")\n",
    "\n",
    "    if len(df) == 0:\n",
    "        raise ValueError(\"Датасет пустой!\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75ec6c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Использую уже имеющийся датасет из директории: C:\\Users\\msi\\DS\\Eye Disease Classification\\dataset\\Augmented Dataset\n",
      "Распределение классов: class\n",
      "Diabetic Retinopathy                             3444\n",
      "Glaucoma                                         2880\n",
      "Healthy                                          2676\n",
      "Myopia                                           2251\n",
      "Macular Scar                                     1937\n",
      "Retinitis Pigmentosa                              834\n",
      "Disc Edema                                        762\n",
      "Retinal Detachment                                750\n",
      "Central Serous Chorioretinopathy-Color Fundus     606\n",
      "Pterygium                                         102\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>class</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\msi\\DS\\Eye Disease Classification\\dat...</td>\n",
       "      <td>Central Serous Chorioretinopathy-Color Fundus</td>\n",
       "      <td>2004</td>\n",
       "      <td>1690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\msi\\DS\\Eye Disease Classification\\dat...</td>\n",
       "      <td>Central Serous Chorioretinopathy-Color Fundus</td>\n",
       "      <td>2004</td>\n",
       "      <td>1690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\msi\\DS\\Eye Disease Classification\\dat...</td>\n",
       "      <td>Central Serous Chorioretinopathy-Color Fundus</td>\n",
       "      <td>2004</td>\n",
       "      <td>1690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\msi\\DS\\Eye Disease Classification\\dat...</td>\n",
       "      <td>Central Serous Chorioretinopathy-Color Fundus</td>\n",
       "      <td>2004</td>\n",
       "      <td>1690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\msi\\DS\\Eye Disease Classification\\dat...</td>\n",
       "      <td>Central Serous Chorioretinopathy-Color Fundus</td>\n",
       "      <td>2004</td>\n",
       "      <td>1690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  \\\n",
       "0  C:\\Users\\msi\\DS\\Eye Disease Classification\\dat...   \n",
       "1  C:\\Users\\msi\\DS\\Eye Disease Classification\\dat...   \n",
       "2  C:\\Users\\msi\\DS\\Eye Disease Classification\\dat...   \n",
       "3  C:\\Users\\msi\\DS\\Eye Disease Classification\\dat...   \n",
       "4  C:\\Users\\msi\\DS\\Eye Disease Classification\\dat...   \n",
       "\n",
       "                                           class  width  height  \n",
       "0  Central Serous Chorioretinopathy-Color Fundus   2004    1690  \n",
       "1  Central Serous Chorioretinopathy-Color Fundus   2004    1690  \n",
       "2  Central Serous Chorioretinopathy-Color Fundus   2004    1690  \n",
       "3  Central Serous Chorioretinopathy-Color Fundus   2004    1690  \n",
       "4  Central Serous Chorioretinopathy-Color Fundus   2004    1690  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_eye_disease_dataset(DATA_DIR)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98628bc1",
   "metadata": {},
   "source": [
    "Разделяем выборку на трейн/тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проиндексируем наши классы\n",
    "class_names = df[\"class\"].unique().tolist()\n",
    "class_idxs = {cls: i for i, cls in enumerate(class_names)}\n",
    "df[\"label\"] = df[\"class\"].map(class_idxs)\n",
    "\n",
    "# Теперь делим на трейн/тест\n",
    "train_part, test_part = train_test_split(\n",
    "    df, test_size=0.2, stratify=df[\"label\"], random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5247c8",
   "metadata": {},
   "source": [
    "Выполняем нормализацию данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbc2ecd",
   "metadata": {},
   "source": [
    "Создаем свой кастомный Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428909fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "class EyeDiseaseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Кастомный датасет\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, transform=None):\n",
    "        self.data = df.reset_index(drop=True)\n",
    "        self.transform = transform or transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.loc[idx, 'path']\n",
    "        image = Image.open(img_path)\n",
    "        label = self.data.loc[idx, 'label']\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = EyeDiseaseDataset(train_part, data_transforms['train'])\n",
    "test_ds = EyeDiseaseDataset(test_part, data_transforms['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206166c",
   "metadata": {},
   "source": [
    "Сделаем балансировку классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c881e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "class_counts = train_part['label'].value_counts().sort_index().values\n",
    "class_weights = 1.0 / class_counts\n",
    "sampler = WeightedRandomSampler(class_weights, len(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facc04fd",
   "metadata": {},
   "source": [
    "Теперь создаем DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=64, sampler=sampler)\n",
    "test_dataloader = DataLoader(test_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dce9c2",
   "metadata": {},
   "source": [
    "Проитерируемся и посмотрим на изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f259a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    plt.imshow(np.clip(img, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c648ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Размерность признаков: {train_features.size()}\")\n",
    "print(f\"Размерность классов: {train_labels.size()}\")\n",
    "\n",
    "for i in range(5):\n",
    "    img = train_features[i]\n",
    "    label = train_labels[i]\n",
    "    imshow(img)\n",
    "    plt.title(class_names[train_labels[i].item()])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1005528d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Определим переменные для построения нейронки\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m num_channels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m()[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m img_width \u001b[38;5;241m=\u001b[39m train_dataloader\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m      4\u001b[0m img_height \u001b[38;5;241m=\u001b[39m train_dataloader\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m3\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "# Определим переменные для построения нейронки\n",
    "num_channels = train_features.size()[1]\n",
    "img_width = train_features.size()[2]\n",
    "img_height = train_features.size()[3]\n",
    "out_features = train_labels.size()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e66a81",
   "metadata": {},
   "source": [
    "Строим модель-бэзлайн - сверточную нейронную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfb6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Нейронная сеть для классификации изображений глазного дна\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 56 * 56, 128),  # 224/4=56\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a6bf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nn_model \u001b[38;5;241m=\u001b[39m NeuralNet(\u001b[43mout_features\u001b[49m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(nn_model)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'out_features' is not defined"
     ]
    }
   ],
   "source": [
    "nn_model = NeuralNet(out_features).to(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(nn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97acb601",
   "metadata": {},
   "source": [
    "Определим функции тренировки модели и визуализации предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61fd506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=1000):\n",
    "    # Create a temporary directory to save training checkpoints\n",
    "    with TemporaryDirectory() as tempdir:\n",
    "        best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "        torch.save(model.state_dict(), best_model_params_path)\n",
    "        best_acc = 0.0\n",
    "        device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        dataset_sizes = {\"train\": len(train_dataloader), \"val\": len(test_dataloader)}\n",
    "        dataloaders = {\"train\": train_dataloader, \"val\": test_dataloader}\n",
    "\n",
    "        print(f\"Обучаю на {device}\")\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch {epoch}/{num_epochs - 1}\")\n",
    "            print(\"-\" * 10)\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in [\"train\", \"val\"]:\n",
    "                if phase == \"train\":\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()  # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                # Iterate over data.\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == \"train\"):\n",
    "                        outputs = model(inputs)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == \"train\":\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "                print(f\"{phase} Loss: {epoch_loss:.4f} Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == \"val\" and epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "            print()\n",
    "\n",
    "        print(f\"Best val Acc: {best_acc:4f}\")\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(torch.load(best_model_params_path, weights_only=True))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b9d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in enumerate(test_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca5d99",
   "metadata": {},
   "source": [
    "Обучаем нашу нейронную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ef6847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439367ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучаю на cpu\n",
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 22.8153 Accuracy: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      2\u001b[0m nn_optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(nn_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m nn_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 42\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# track history if only in train\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 42\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     44\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[15], line 22\u001b[0m, in \u001b[0;36mNeuralNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py:101\u001b[0m, in \u001b[0;36mReLU.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1473\u001b[0m, in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m   1471\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu_(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m   1472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1473\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "nn_optimizer = optim.Adam(nn_model.parameters(), lr=0.001)\n",
    "\n",
    "nn_model = train_model(nn_model, criterion, nn_optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d062df",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(nn_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
